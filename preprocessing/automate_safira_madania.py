# -*- coding: utf-8 -*-
"""automate_Safira-Madania

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u5Rt1GUdC9zyVbmufQZmrCjQN5Urow9Q
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from joblib import dump
from scipy.io import arff
import os

def load_arff_data(file_path):
    # Load file arff
    data, meta = arff.loadarff(file_path)
    df = pd.DataFrame(data)

    return df

def automate_preprocessing(df, target_column, save_path='preprocessor.joblib'):
    # 1. Label Encoding & Mapping
    if df[target_column].dtype == object:
        try:
            df[target_column] = df[target_column].str.decode('utf-8').astype(int)
        except: pass
    df[target_column] = df[target_column].replace(-1, 0)

    # 2. Drop Duplicates
    df = df.drop_duplicates().reset_index(drop=True)

    # 3. Multikolinearitas & Fitur RT(skor)
    X_raw = df.drop(columns=[target_column])
    corr_matrix = X_raw.corr().abs()
    upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))

    # Cari yang korelasi > 0.8
    to_drop_multi = [col for col in upper_tri.columns if any(upper_tri[col] > 0.80)]
    # Cari yang akhiran RT
    to_drop_skor = [c for c in X_raw.columns if c.endswith('RT')]

    final_drop = list(set(to_drop_multi + to_drop_skor))

    df_final = df.drop(columns=final_drop)

    X = df_final.drop(target_column, axis=1)
    y = df_final[target_column].replace(-1, 0)

    # Simpan daftar kolom akhir ke variabel
    list_kolom_final = X.columns.tolist()

    # 4. Split Data
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)

    # 5. Identifikasi Binary & Numerik
    kolom_binary = [c for c in X.columns if X[c].nunique() <= 2]
    kolom_numerik = [c for c in X.columns if X[c].nunique() > 2]

    # 6. Transformasi
    transformer = ColumnTransformer([
        ('num', StandardScaler(), kolom_numerik),
        ('bin', 'passthrough', kolom_binary)
    ])

    X_train_p = transformer.fit_transform(X_train)
    X_val_p   = transformer.transform(X_val)
    X_test_p  = transformer.transform(X_test)

    # 7. SIMPAN SEMUA DALAM SATU FILE
    metadata = {
        'transformer_object': transformer,
        'final_columns': list_kolom_final
    }

    dump(metadata, save_path)
    print(f"--- PREPROCESSING SELESAI ---")
    print(f"Fitur dibuang   : {len(final_drop)} kolom")
    print(f"File disimpan ke: {save_path}")

    return X_train_p, X_val_p, X_test_p, y_train, y_val, y_test

if __name__ == "__main__":

    # Path folder
    raw_path = 'phising_raw/phishing_dataset.arff'
    output_folder = 'preprocessing/phishing_preprocessing/'

    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # Load data
    df = load_arff_data(raw_path)

    # Jalankan preprocessing
    X_train, X_val, X_test, y_train, y_val, y_test = automate_preprocessing(
        df,
        target_column='CLASS_LABEL',
        save_path=os.path.join(output_folder, 'preprocessor.joblib')
    )

    # Simpan hasil X (sudah ada di kode kamu)
    pd.DataFrame(X_train).to_csv(os.path.join(output_folder, 'X_train_processed.csv'), index=False)
    pd.DataFrame(X_val).to_csv(os.path.join(output_folder, 'X_val_processed.csv'), index=False)
    pd.DataFrame(X_test).to_csv(os.path.join(output_folder, 'X_test_processed.csv'), index=False)

    # TAMBAHKAN BARIS INI: Simpan hasil y (label)
    pd.DataFrame(y_train).to_csv(os.path.join(output_folder, 'y_train.csv'), index=False)
    pd.DataFrame(y_val).to_csv(os.path.join(output_folder, 'y_val.csv'), index=False)
    pd.DataFrame(y_test).to_csv(os.path.join(output_folder, 'y_test.csv'), index=False)
    
    print("Semua file X dan y berhasil disimpan!")
    print("Preprocessing via GitHub Actions Berhasil!")

